{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "This notebook contains two example workflows, both based on matching two versions of S&P 500 companies. Data can be downloaded with the code in the notebook `downloads.ipynb` in the same folder.\n",
    "\n",
    "Currently, only core functions are implemented in the library, so that there is a lot of administrational code. This will make its way into higher-level interfaces in the library itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from ptfidf import utils as ut\n",
    "from ptfidf.train.aggregation import get_group_statistics, compress_group_statistics\n",
    "from ptfidf.train.inference import map_estimate\n",
    "from ptfidf.core import get_log_proba, get_log_prior, get_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_training_data(names, target, matched_symbols):\n",
    "    \"\"\"\n",
    "    Label training data.\n",
    "    \n",
    "    Names with symbol in matched_symbols will be assigned to \n",
    "    the same entity (per symbol).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    names : pandas.DataFrame\n",
    "        columns ['source', 'symbol', ...]\n",
    "    target : str\n",
    "        value of source that is to be considered target list\n",
    "    matched_symbols : sequence or int\n",
    "        if sequence, these symbols are matched. If int,\n",
    "        draw matched_symbols symbols randomly.\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        values are '{source}:{symbol}' where source equals target for\n",
    "        matched symbols.\n",
    "    \"\"\"\n",
    "    if isinstance(matched_symbols, int):\n",
    "        matched_symbols = np.random.choice(np.unique(names['symbol']), replace=False, size=matched_symbols)\n",
    "    res = pd.Series(index=names.index, name='entity')\n",
    "    idx = names['symbol'].isin(matched_symbols)\n",
    "    res.loc[idx] = target + ':' + names.loc[idx, 'symbol']\n",
    "    res.loc[~idx] = names.loc[~idx, 'source'] + ':' + names.loc[~idx, 'symbol']\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_evaluation_data(proba, correct_assignments):\n",
    "    correct_assignments = pd.DataFrame(correct_assignments, columns=['row', 'col'])\n",
    "    auc_data = ut.sparse_to_frame(proba).merge(correct_assignment.assign(y=1), on=['row', 'col'], how='left')\n",
    "    auc_data['y'] = auc_data['y'].fillna(0).astype(int)\n",
    "    return auc_data.rename(columns={'data': 'score'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading / Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files and concatenate into single table\n",
    "datadir = Path('../data').resolve()\n",
    "filenames = ['wikipedia.csv', 'slickcharts.csv']\n",
    "names = pd.concat([\n",
    "    pd.read_csv(datadir.joinpath(fn)).assign(source=fn.split('.')[0]) for fn in filenames\n",
    "], axis=0).sort_values(['symbol', 'source']).reset_index(drop=True)\n",
    "\n",
    "# drop some symbols that are impossible to get correct with current preprocessing\n",
    "\n",
    "# These differ only in appended Class <X>, where <X> is a single letter that is \n",
    "# dropped in the preprocessing\n",
    "duplicate_companies = ['GOOGL', 'NWSA', 'DISCA', 'FOXA', 'UAA']\n",
    "# No (or almost no) token overlap due to spelling variations\n",
    "impossible_symbols = ['VFC', 'PHM', 'UNH', 'LLL']\n",
    "names = names[~names['symbol'].isin(duplicate_companies + impossible_symbols)]\n",
    "\n",
    "# vectorize\n",
    "vec = CountVectorizer(binary=True).fit(names['name'])\n",
    "X = vec.transform(names['name'])\n",
    "vocabulary_inv = {v: k for k, v in vec.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Training\n",
    "\n",
    "For online training, companies are labeled correctly one by one - here in batches of 20. After each batch is labelled by the user, the predictions for the next batch are based on updated parameters from all preceding examples.\n",
    "\n",
    "The figures below show the change of prediction quality effected through online training. For this small example, most predictions are pretty good without training. For most examples with low initial scores, there is a noticeable improvement. While effects vary depending on the order of batches, the overall effect is very stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "symbols = np.random.permutation(np.unique(names['symbol']))\n",
    "prior = (np.log(.2), 1.5)\n",
    "batch_size = 20\n",
    "log_odds_in_list = np.log(10.)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "res = pd.DataFrame()\n",
    "pi, s = None, None\n",
    "for train_size in range(0, symbols.size, batch_size):\n",
    "    labels = label_training_data(names, 'wikipedia', symbols[:train_size])\n",
    "\n",
    "    y = encoder.fit_transform(labels.values)\n",
    "    counts, n_observations = get_group_statistics(X, y)\n",
    "    is_test = np.array([s.startswith('slickcharts') for s in encoder.classes_])\n",
    "    is_target = ~is_test\n",
    "    pi, s = map_estimate(*compress_group_statistics(counts, n_observations), *prior, s_init=s, pi_init=pi)\n",
    "    \n",
    "    log_proba = get_log_proba(counts[is_test], counts[is_target], n_observations[is_target], pi, s)\n",
    "    log_prior = get_log_prior(counts[is_test], pi)\n",
    "    proba = get_proba(log_proba, log_prior, log_odds=log_odds_in_list)\n",
    "    \n",
    "    test_classes, target_classes = [{\n",
    "        s.split(':')[-1]: i for i, s in enumerate(encoder.classes_[idx])}\n",
    "        for idx in [is_test, is_target]]\n",
    "\n",
    "    score = pd.Series({k: proba[test_classes[k], target_classes[k]] for k in test_classes}).sort_values()\n",
    "    res = res.append(score.reset_index().rename(columns={'index': 'symbol', 0: 'proba'}).assign(train_size=train_size))\n",
    "online_scores = res.sort_values(['symbol', 'train_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "for _, df in online_scores.groupby('symbol'):\n",
    "    ax.plot(df['train_size'].values, df['proba'].values, 'k-', alpha=.2)\n",
    "\n",
    "ax.set_ylim((-.05, 1.05))\n",
    "ax.grid()\n",
    "ax.set_xlabel('matched examples')\n",
    "ax.set_ylabel('predicted probability')\n",
    "ax.set_title('prediction quality vs training set size\\nup to prediction time')\n",
    "\n",
    "ax = axes[1]\n",
    "online_change = online_scores.groupby('symbol')['proba'].agg(['first', 'last'])\n",
    "ax.plot(online_change['first'], online_change['last'], '.', alpha=.7)\n",
    "ax.plot([0, 1], [0, 1], 'k:')\n",
    "ax.grid()\n",
    "ax.set_title('predicted probability of correct match\\nwhen example is labeled')\n",
    "ax.set_xlabel('before training')\n",
    "ax.set_ylabel('after online training')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "Instead of manually labelling examples, in unsupervised learing we use Expectation-Maximization to train parameters. We iteratively assign names randomly from the predictive distribution and update parameters using the resulting averaged entity statistics.\n",
    "\n",
    "Here, we use a poor man's implementation that does not update entity statistics for simplicity. Instead, only global word-level parameters are maintained. We use a single matching sample to obtain the word-level statistics.\n",
    "\n",
    "While results are not as good as for online learning (as expected), there are still marked improvements without manual input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "encoder = LabelEncoder()\n",
    "prior = (np.log(.2), 1.5)\n",
    "log_odds_in_list = np.log(10.)\n",
    "learning_rate = .4\n",
    "unsupervised_steps = 20\n",
    "\n",
    "is_train = (names['source'] == 'slickcharts').values\n",
    "is_target = ~is_train\n",
    "\n",
    "test_classes = {s: i for i, s in enumerate(names[is_train]['symbol'])}\n",
    "target_classes = {s: i for i, s in enumerate(names[is_target]['symbol'])}\n",
    "correct_assignments = [(test_classes[k], target_classes[k]) for k in test_classes]\n",
    "\n",
    "n_observations = np.ones(is_target.sum(), dtype=int)\n",
    "\n",
    "\n",
    "# init with no assignments\n",
    "pi, s = map_estimate(*compress_group_statistics(X, np.ones(X.shape[0], dtype=int)), *prior)\n",
    "\n",
    "res = pd.DataFrame()\n",
    "for step in range(unsupervised_steps + 1):\n",
    "    # compute random assignments with current parameters\n",
    "    log_proba = get_log_proba(X[is_train], X[is_target], n_observations, pi, s)\n",
    "    log_prior = get_log_prior(X[is_train], pi)\n",
    "    proba = get_proba(log_proba, log_prior, log_odds_in_list)\n",
    "    \n",
    "    # record scores\n",
    "    if step == 0:\n",
    "        initial_evaluation_data = get_evaluation_data(proba, correct_assignments)\n",
    "    score = pd.Series({k: proba[test_classes[k], target_classes[k]] for k in test_classes})\n",
    "    res = res.append(score.reset_index().rename(columns={'index': 'symbol', 0: 'proba'}).assign(step=step))\n",
    "\n",
    "    # create entity labels\n",
    "    idx_in_list = np.random.rand(proba.shape[0]) < np.array(proba.sum(axis=1)).ravel()\n",
    "    idx_train = np.where(is_train)[0]\n",
    "    y = np.empty(X.shape[0], dtype=int)\n",
    "    for i in np.where(idx_in_list)[0]:\n",
    "        lo, hi = proba.indptr[i], proba.indptr[i + 1]\n",
    "        y[idx_train[i]] = np.random.choice(proba.indices[lo:hi], p=proba.data[lo:hi] / proba.data[lo:hi].sum())\n",
    "    y[idx_train[~idx_in_list]] = proba.shape[1] + np.arange(np.sum(~idx_in_list))\n",
    "    y[is_target] = np.arange(is_target.sum())\n",
    "\n",
    "    # update parameters\n",
    "    counts, nobs = get_group_statistics(X, y)\n",
    "    pi_new, s_new = map_estimate(*compress_group_statistics(counts, nobs), *prior, s_init=s, pi_init=pi)\n",
    "    _learning_rate = learning_rate / (step + 1.)\n",
    "    pi *= (1. - _learning_rate)\n",
    "    pi += _learning_rate * pi_new\n",
    "    s *= (1. - _learning_rate)\n",
    "    s += _learning_rate * s_new\n",
    "\n",
    "unsupervised_scores = res.sort_values(['symbol', 'step'])\n",
    "final_evaluation_data = get_evaluation_data(proba, correct_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "for _, df in unsupervised_scores.groupby('symbol'):\n",
    "    ax.plot(df['step'].values, df['proba'].values, 'k-', alpha=.2)\n",
    "\n",
    "ax.set_ylim((-.05, 1.05))\n",
    "ax.grid()\n",
    "ax.set_xlabel('EM step')\n",
    "ax.set_ylabel('score')\n",
    "ax.set_title('evolution of scores with unsupervised training')\n",
    "\n",
    "ax = axes[1]\n",
    "unsupervised_change = unsupervised_scores.groupby('symbol')['proba'].agg(['first', 'last'])\n",
    "ax.plot(unsupervised_change['first'], change['last'], '.', alpha=.7)\n",
    "ax.plot([0, 1], [0, 1], 'k:')\n",
    "ax.grid()\n",
    "ax.set_title('predicted probability of correct match')\n",
    "ax.set_xlabel('before training')\n",
    "ax.set_ylabel('after unsupervised training')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, figsize=(7, 6), sharex=True, sharey=True)\n",
    "\n",
    "for ax, df, title in zip(axes, [initial_evaluation_data, final_evaluation_data], ['before training', 'after training']):\n",
    "    for (_y, _df), label in zip(df.groupby('y'), ['negative', 'positive']):\n",
    "        ax.hist(_df['score'].values, bins=np.linspace(-.01, 1.01, 21), alpha=.5, density=True, log=True, label=label)\n",
    "        ax.text(.5, .95, title, ha='center', va='top', transform=ax.transAxes, fontsize=12)\n",
    "        \n",
    "axes[0].legend(loc='upper left')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = unsupervised_change.join(online_change, lsuffix='_unsupervised', rsuffix='_online')\n",
    "assert np.allclose(comparison['first_unsupervised'], comparison['first_online'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.set_title('scores for\\nunsupervised learning vs online training')\n",
    "ax.set_xlabel('unsupervised')\n",
    "ax.set_ylabel('online')\n",
    "\n",
    "ax.plot(comparison['last_unsupervised'], comparison['last_online'], '.', alpha=.7)\n",
    "ax.set_aspect(1)\n",
    "lim = (-.05, 1.05)\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.plot(lim, lim, 'k:')\n",
    "ax.grid()\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
